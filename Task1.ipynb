{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN3063 Group 2 Coursework Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Imports](#Imports:) \n",
    "2. [Dataset Selection and description](#a-dataset-selection-and-description)\n",
    "3. [Implement sigmoid and ReLU layers](#b-implement-sigmoid-and-relu-layers)\n",
    "4. [Implement dropout](#d-implement-dropout)\n",
    "5. [Implement a fully parameterizable neural network class](#e-implement-a-fully-parametrizable-neural-network-class)\n",
    "6. [Implement optimizer](#f-implement-optimizer)\n",
    "7. [Evaluate different neural network architectures/parameters present and discuss your results](#g-evaluate-different-neural-network-architecturesparameters-present-and-discuss-your-results)\n",
    "8. [Code quality and report and presentation](#h-code-quality-and-report-presentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Dataset selection and description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Implement sigmoid and ReLU layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Implement softmax layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the softmax layer is to convert raw scores (logits) from the neural network into probabilites that sum to 1.\n",
    "\n",
    "Here is the softmax formula: $ f(z)_i = \\frac{(e^z)_i}{\\Sigma_j^K(e^z)_j} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SoftmaxLayer:\n",
    "    self.output = None\n",
    "    self.input = None\n",
    "    self.dinputs = None\n",
    "\n",
    "    def forward_pass(self, inputs):\n",
    "        self.input = inputs\n",
    "        inputs_stable = inputs - np.max(inputs, axis=1, keepdims=True) # stabalize inputs as exponentials grow very large or very small (numerical overflow/underflow)\n",
    "        exp_values = np.exp(inputs_stable)\n",
    "        self.output = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        return self.output\n",
    "    \n",
    "    def backward_pass(self, dvalues, true_labels):\n",
    "        samples = dvalues.shape[0] # batch size\n",
    "        self.dinputs = (self.output - true_labels) / samples\n",
    "        return self.dinputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Implement dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the dropout layer is to improve the model's generalization and reduce overfitting by randomly temporarily disabling a fraction of the neurons during training, to prevent the model over-relying on specific neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DropoutLayer:\n",
    "    def __init__(self, rate):\n",
    "        self.rate = rate\n",
    "        self.mask = None\n",
    "\n",
    "    def forward_pass(self, inputs, training=True):\n",
    "        if training:\n",
    "            self.mask = (np.random.rand(*inputs.shape) > self.rate) / (1 - self.rate)\n",
    "            return inputs * self.mask\n",
    "        else:\n",
    "            return inputs\n",
    "    \n",
    "    def backward_pass(self, dvalues):\n",
    "        return dvalues * self.mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e) Implement a fully parametrizable neural network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f) Implement optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## g) Evaluate different neural network architectures/parameters, present and discuss your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h) Code quality and report presentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
